import requests
from bs4 import BeautifulSoup
import os
import re

# ============================================================
#   CONFIGURATION â€” Loaded from GitHub Secrets automatically
# ============================================================
TELEGRAM_BOT_TOKEN  = os.environ.get("TELEGRAM_BOT_TOKEN", "")
TELEGRAM_CHANNEL_ID = os.environ.get("TELEGRAM_CHANNEL_ID", "")
TOP_DEALS_COUNT     = 5
# ============================================================

HEADERS = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# HELPERS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_discount(text: str) -> int:
    matches = re.findall(r'(\d{1,3})\s*%\s*off', text.lower())
    if matches:
        return max(int(m) for m in matches if 5 <= int(m) <= 95)
    matches2 = re.findall(r'(?:upto|flat|get|save)\s*(\d{1,3})\s*%', text.lower())
    if matches2:
        return max(int(m) for m in matches2 if 5 <= int(m) <= 95)
    return 0

def extract_prices_inr(text: str) -> list:
    prices = []
    for pattern in [r'â‚¹\s*([\d,]+)', r'Rs\.?\s*([\d,]+)', r'INR\s*([\d,]+)']:
        for m in re.findall(pattern, text):
            try:
                val = int(m.replace(",", ""))
                if 10 < val < 10000000:  # Filter out junk numbers
                    prices.append(val)
            except:
                pass
    return sorted(set(prices))

def get_platform(text: str) -> str:
    t = text.lower()
    if "flipkart" in t:
        return "Flipkart"
    return "Amazon India"

def is_deal_article(text: str) -> bool:
    deal_words = ["deal", "offer", "discount", "% off", "sale", "price drop", "loot", "buy"]
    return any(w in text.lower() for w in deal_words)

def calculate_discount(deal_price, original_price) -> int:
    if deal_price and original_price and original_price > deal_price:
        return int(((original_price - deal_price) / original_price) * 100)
    return 0

def send_to_telegram(message: str):
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    try:
        r = requests.post(url, json={
            "chat_id"                : TELEGRAM_CHANNEL_ID,
            "text"                   : message,
            "parse_mode"             : "HTML",
            "disable_web_page_preview": True,
        }, timeout=10)
        if r.status_code == 200:
            print("âœ… Sent to Telegram!")
        else:
            print(f"âŒ Telegram Error: {r.text}")
    except Exception as e:
        print(f"âŒ Exception: {e}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SOURCE 1 â€” Desidime RSS (Best India Deal Source!)
# Real Amazon.in + Flipkart deals posted by Indian users
# With actual product names, MRP and deal prices in â‚¹
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_desidime() -> list:
    print("\nğŸ” Fetching Desidime deals...")
    deals = []

    # Multiple category RSS feeds from Desidime
    rss_feeds = [
        "https://www.desidime.com/deals.rss",                          # All deals
        "https://www.desidime.com/selective_search/electronics.rss",    # Electronics
        "https://www.desidime.com/selective_search/mobiles.rss",        # Mobiles
        "https://www.desidime.com/selective_search/fashion.rss",        # Fashion
        "https://www.desidime.com/selective_search/home-kitchen.rss",   # Home & Kitchen
        "https://www.desidime.com/selective_search/freebies.rss",       # Freebies/Loot
    ]

    for feed_url in rss_feeds:
        try:
            r    = requests.get(feed_url, headers={"User-Agent": "Mozilla/5.0"}, timeout=15)
            soup = BeautifulSoup(r.text, "xml")
            items = soup.find_all("item")
            print(f"   {feed_url.split('/')[-1]} â†’ {len(items)} items")

            for item in items:
                try:
                    title    = item.find("title").get_text(strip=True)      if item.find("title")       else ""
                    link     = item.find("link").get_text(strip=True)        if item.find("link")        else ""
                    desc     = item.find("description").get_text(strip=True) if item.find("description") else ""
                    combined = title + " " + desc

                    discount = extract_discount(combined)
                    prices   = extract_prices_inr(combined)

                    deal_price     = prices[0]  if len(prices) >= 1 else None
                    original_price = prices[-1] if len(prices) >= 2 else None

                    # Calculate discount from prices if not mentioned explicitly
                    if discount == 0 and deal_price and original_price:
                        discount = calculate_discount(deal_price, original_price)

                    deals.append({
                        "title"         : title[:80],
                        "link"          : link,
                        "discount"      : discount,
                        "deal_price"    : deal_price,
                        "original_price": original_price,
                        "platform"      : get_platform(combined),
                        "source"        : "Desidime"
                    })
                except:
                    continue

        except Exception as e:
            print(f"   âŒ Error {feed_url}: {e}")

    print(f"   âœ… Desidime total â€” {len(deals)} deals collected")
    return deals


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SOURCE 2 â€” Coupondunia India
# Real Amazon.in + Flipkart product deals with prices in â‚¹
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_coupondunia() -> list:
    print("\nğŸ” Fetching Coupondunia deals...")
    deals = []
    try:
        r    = requests.get("https://coupondunia.in/blog/feed/",
                            headers={"User-Agent": "Mozilla/5.0"}, timeout=15)
        soup = BeautifulSoup(r.text, "xml")
        items = soup.find_all("item")
        print(f"   Found {len(items)} items")

        for item in items:
            try:
                title    = item.find("title").get_text(strip=True)      if item.find("title")       else ""
                link     = item.find("link").get_text(strip=True)        if item.find("link")        else ""
                desc     = item.find("description").get_text(strip=True) if item.find("description") else ""
                combined = title + " " + desc

                # Skip if not a deal article
                if not is_deal_article(combined):
                    continue

                discount = extract_discount(combined)
                prices   = extract_prices_inr(combined)

                deal_price     = prices[0]  if len(prices) >= 1 else None
                original_price = prices[-1] if len(prices) >= 2 else None

                if discount == 0 and deal_price and original_price:
                    discount = calculate_discount(deal_price, original_price)

                deals.append({
                    "title"         : title[:80],
                    "link"          : link,
                    "discount"      : discount,
                    "deal_price"    : deal_price,
                    "original_price": original_price,
                    "platform"      : get_platform(combined),
                    "source"        : "Coupondunia"
                })
            except:
                continue

    except Exception as e:
        print(f"   âŒ Coupondunia error: {e}")

    print(f"   âœ… Coupondunia â€” {len(deals)} deals collected")
    return deals


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SOURCE 3 â€” GrabOn India
# Amazon.in + Flipkart deals, coupons, offers in â‚¹
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_grabon() -> list:
    print("\nğŸ” Fetching GrabOn deals...")
    deals = []
    try:
        r    = requests.get("https://www.grabon.in/indias-best-deals/feed/",
                            headers={"User-Agent": "Mozilla/5.0"}, timeout=15)
        soup = BeautifulSoup(r.text, "xml")
        items = soup.find_all("item")
        print(f"   Found {len(items)} items")

        for item in items:
            try:
                title    = item.find("title").get_text(strip=True)      if item.find("title")       else ""
                link     = item.find("link").get_text(strip=True)        if item.find("link")        else ""
                desc     = item.find("description").get_text(strip=True) if item.find("description") else ""
                combined = title + " " + desc

                if not is_deal_article(combined):
                    continue

                discount = extract_discount(combined)
                prices   = extract_prices_inr(combined)

                deal_price     = prices[0]  if len(prices) >= 1 else None
                original_price = prices[-1] if len(prices) >= 2 else None

                if discount == 0 and deal_price and original_price:
                    discount = calculate_discount(deal_price, original_price)

                deals.append({
                    "title"         : title[:80],
                    "link"          : link,
                    "discount"      : discount,
                    "deal_price"    : deal_price,
                    "original_price": original_price,
                    "platform"      : get_platform(combined),
                    "source"        : "GrabOn"
                })
            except:
                continue

    except Exception as e:
        print(f"   âŒ GrabOn error: {e}")

    print(f"   âœ… GrabOn â€” {len(deals)} deals collected")
    return deals


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SOURCE 4 â€” 91mobiles Deals RSS
# Only deal articles â€” mobiles + electronics on Amazon/Flipkart
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_91mobiles() -> list:
    print("\nğŸ” Fetching 91mobiles deals...")
    deals = []
    try:
        r    = requests.get("https://www.91mobiles.com/hub/deals/feed/",
                            headers={"User-Agent": "Mozilla/5.0"}, timeout=15)
        soup = BeautifulSoup(r.text, "xml")
        items = soup.find_all("item")
        print(f"   Found {len(items)} items")

        for item in items:
            try:
                title    = item.find("title").get_text(strip=True)      if item.find("title")       else ""
                link     = item.find("link").get_text(strip=True)        if item.find("link")        else ""
                desc     = item.find("description").get_text(strip=True) if item.find("description") else ""
                combined = title + " " + desc

                discount = extract_discount(combined)
                prices   = extract_prices_inr(combined)

                deal_price     = prices[0]  if len(prices) >= 1 else None
                original_price = prices[-1] if len(prices) >= 2 else None

                if discount == 0 and deal_price and original_price:
                    discount = calculate_discount(deal_price, original_price)

                deals.append({
                    "title"         : title[:80],
                    "link"          : link,
                    "discount"      : discount,
                    "deal_price"    : deal_price,
                    "original_price": original_price,
                    "platform"      : get_platform(combined),
                    "source"        : "91mobiles"
                })
            except:
                continue

    except Exception as e:
        print(f"   âŒ 91mobiles error: {e}")

    print(f"   âœ… 91mobiles â€” {len(deals)} deals collected")
    return deals


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SEND TOP 5 AS ONE CLEAN MESSAGE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def send_top5(deals: list):
    medals  = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰", "ğŸ”¥", "ğŸ’¥"]
    message = "ğŸ‡®ğŸ‡³ <b>TOP 5 DEALS â€” Amazon India &amp; Flipkart</b>\n"
    message += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"

    for i, deal in enumerate(deals):
        medal = medals[i] if i < len(medals) else "ğŸ”¥"
        message += f"{medal} <b>#{i+1} â€” {deal['platform']}</b>\n"
        message += f"ğŸ“¦ {deal['title']}\n"

        if deal['original_price'] and deal['deal_price'] and deal['original_price'] != deal['deal_price']:
            message += f"ğŸ·ï¸ MRP: <s>â‚¹{deal['original_price']:,}</s>  ğŸ’° <b>â‚¹{deal['deal_price']:,}</b>\n"
        elif deal['deal_price']:
            message += f"ğŸ’° Price: <b>â‚¹{deal['deal_price']:,}</b>\n"

        if deal['discount'] > 0:
            message += f"ğŸ“‰ You Save: <b>{deal['discount']}% OFF</b>\n"

        message += f"ğŸ›’ <a href='{deal['link']}'>Buy Now â†’</a>\n"
        message += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"

    message += "â° <i>Next scan in 6 hours!</i>"
    send_to_telegram(message)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MAIN
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    print("\n" + "="*50)
    print("ğŸš€ India Deal Finder Started!")
    print(f"   Market    : Amazon India + Flipkart (â‚¹ only)")
    print(f"   Top Deals : Top {TOP_DEALS_COUNT} per run â€” 1 message only")
    print(f"   Channel   : {TELEGRAM_CHANNEL_ID}")
    print("="*50)

    # Collect from all proper India deal sources
    all_deals = []
    all_deals += fetch_desidime()    # Best source â€” real community deals
    all_deals += fetch_91mobiles()   # Tech deals
    all_deals += fetch_coupondunia() # India deals site
    all_deals += fetch_grabon()      # India deals site

    print(f"\nğŸ“Š Total deals collected from all sources: {len(all_deals)}")

    if not all_deals:
        send_to_telegram(
            "â„¹ï¸ <b>Scan Complete!</b>\n"
            "No deals found this round.\n"
            "ğŸ• Will check again in 6 hours!"
        )
        return

    # Sort by highest discount first
    all_deals.sort(key=lambda x: x["discount"], reverse=True)

    # Remove duplicates by title
    seen, unique = set(), []
    for deal in all_deals:
        key = deal["title"][:25].lower().strip()
        if key not in seen:
            seen.add(key)
            unique.append(deal)

    # Pick top 5
    top5 = unique[:TOP_DEALS_COUNT]

    print(f"\nğŸ† Top {len(top5)} deals selected:")
    for i, d in enumerate(top5, 1):
        print(f"   {i}. {d['discount']}% off â€” {d['title'][:50]} [{d['source']}]")

    send_top5(top5)


if __name__ == "__main__":
    main()
